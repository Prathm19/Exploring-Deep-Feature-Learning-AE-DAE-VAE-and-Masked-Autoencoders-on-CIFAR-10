{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-1: Standard Autoencoder (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to build a standard Autoencoder (AE) to learn meaningful representations\n",
    "from the CIFAR-10 dataset.\n",
    "1. The encoder should consist of convolutional layers for feature extraction.\n",
    "2. The decoder should use transpose convolutions (ConvTranspose2D) to reconstruct\n",
    "images.\n",
    "3. Train the model using Mean Squared Error (MSE) loss.\n",
    "Task:\n",
    "1. Train the AE on CIFAR-10 and evaluate reconstruction quality on test data(using\n",
    "SSIM,PSNR,MAE,MSE).\n",
    "2. Visualize latent space representations using t-SNE or PCA.\n",
    "Presentation of Results:\n",
    "● Visualize original vs. reconstructed images.\n",
    "● Plot average error (y-axis) vs. epochs (x-axis).\n",
    "Date: 01/04/2025\n",
    "\n",
    "● Compare latent space structure for clean vs. noisy input images.\n",
    "● Discuss the effectiveness of autoencoders in feature learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If available, print GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Config ------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "LATENT_DIM = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [17:34<00:00, 162kB/s]  \n"
     ]
    }
   ],
   "source": [
    "# ------------------ Data ------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Autoencoder ------------------\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        recon = self.decoder(latent)\n",
    "        return recon, latent\n",
    "\n",
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Loss: 0.0163\n",
      "Epoch [2/20] Loss: 0.0064\n",
      "Epoch [3/20] Loss: 0.0050\n",
      "Epoch [4/20] Loss: 0.0040\n",
      "Epoch [5/20] Loss: 0.0034\n",
      "Epoch [6/20] Loss: 0.0030\n",
      "Epoch [7/20] Loss: 0.0027\n",
      "Epoch [8/20] Loss: 0.0025\n",
      "Epoch [9/20] Loss: 0.0023\n",
      "Epoch [10/20] Loss: 0.0022\n",
      "Epoch [11/20] Loss: 0.0020\n",
      "Epoch [12/20] Loss: 0.0019\n",
      "Epoch [13/20] Loss: 0.0018\n",
      "Epoch [14/20] Loss: 0.0017\n",
      "Epoch [15/20] Loss: 0.0017\n",
      "Epoch [16/20] Loss: 0.0016\n",
      "Epoch [17/20] Loss: 0.0015\n",
      "Epoch [18/20] Loss: 0.0015\n",
      "Epoch [19/20] Loss: 0.0014\n",
      "Epoch [20/20] Loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Training ------------------\n",
    "train_errors = []\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for inputs, _ in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(trainloader)\n",
    "    train_errors.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7332\\1855382213.py:6: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7332\\1855382213.py:10: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Plot training error\n",
    "plt.plot(train_errors)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Error')\n",
    "plt.title('Error vs. Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mse_loss_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "originals, reconstructions, latent_vectors, labels = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in testloader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs, latents = model(inputs)\n",
    "        originals.append(inputs.cpu())\n",
    "        reconstructions.append(outputs.cpu())\n",
    "        latent_vectors.append(latents.view(latents.size(0), -1).cpu())\n",
    "        labels.append(targets)\n",
    "\n",
    "originals = torch.cat(originals)\n",
    "reconstructions = torch.cat(reconstructions)\n",
    "latent_vectors = torch.cat(latent_vectors)\n",
    "labels = torch.cat(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SSIM: 0.9322\n",
      "Average PSNR: 28.5033\n",
      "Average MAE: 0.0293\n",
      "Average MSE: 0.0016\n"
     ]
    }
   ],
   "source": [
    "# SSIM, PSNR, MAE, MSE\n",
    "ssim_vals, psnr_vals, mae_vals, mse_vals = [], [], [], []\n",
    "\n",
    "for orig, recon in zip(originals, reconstructions):\n",
    "    orig_np = orig.permute(1, 2, 0).numpy()\n",
    "    recon_np = recon.permute(1, 2, 0).numpy()\n",
    "\n",
    "    ssim_val = ssim(orig_np, recon_np, win_size=7, channel_axis=-1, data_range=1.0)\n",
    "    psnr_val = psnr(orig_np, recon_np, data_range=1.0)\n",
    "    mae_val = mean_absolute_error(orig_np.flatten(), recon_np.flatten())\n",
    "    mse_val = mean_squared_error(orig_np.flatten(), recon_np.flatten())\n",
    "\n",
    "    ssim_vals.append(ssim_val)\n",
    "    psnr_vals.append(psnr_val)\n",
    "    mae_vals.append(mae_val)\n",
    "    mse_vals.append(mse_val)\n",
    "\n",
    "print(f\"Average SSIM: {np.mean(ssim_vals):.4f}\")\n",
    "print(f\"Average PSNR: {np.mean(psnr_vals):.4f}\")\n",
    "print(f\"Average MAE: {np.mean(mae_vals):.4f}\")\n",
    "print(f\"Average MSE: {np.mean(mse_vals):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7332\\884460511.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Visualize Reconstructions ------------------\n",
    "\n",
    "def imshow_tensor(tensor):\n",
    "    npimg = tensor.numpy().transpose(1, 2, 0)\n",
    "    return np.clip(npimg, 0, 1)\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(8, 12), dpi=300)\n",
    "for i in range(5):\n",
    "    axes[i, 0].imshow(imshow_tensor(originals[i]))\n",
    "    axes[i, 0].set_title(\"Original\", fontsize=10)\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    axes[i, 1].imshow(imshow_tensor(reconstructions[i]))\n",
    "    axes[i, 1].set_title(\"Reconstructed\", fontsize=10)\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"original_vs_reconstructed.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7332\\530110678.py:10: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Latent Space Visualization ------------------\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "latent_pca = pca.fit_transform(latent_vectors)\n",
    "plt.scatter(latent_pca[:, 0], latent_pca[:, 1], c=labels, cmap='tab10', s=10)\n",
    "plt.title(\"Latent Space (PCA)\")\n",
    "plt.colorbar()\n",
    "plt.savefig('latent_pca.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7332\\222940577.py:12: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "latent_pca = pca.fit_transform(latent_vectors)\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "scatter = plt.scatter(latent_pca[:, 0], latent_pca[:, 1], c=labels, cmap='tab10', s=15)\n",
    "plt.title(\"Latent Space (PCA)\", fontsize=12)\n",
    "plt.colorbar(scatter)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"latent_space_pca.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7332\\4228839093.py:8: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "latent_tsne = tsne.fit_transform(latent_vectors)\n",
    "plt.scatter(latent_tsne[:, 0], latent_tsne[:, 1], c=labels, cmap='tab10', s=10)\n",
    "plt.title(\"Latent Space (t-SNE)\")\n",
    "plt.colorbar()\n",
    "plt.savefig('latent_tsne.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7332\\2968786648.py:12: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "latent_tsne = tsne.fit_transform(latent_vectors)\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "scatter = plt.scatter(latent_tsne[:, 0], latent_tsne[:, 1], c=labels, cmap='tab10', s=15)\n",
    "plt.title(\"Latent Space (t-SNE)\", fontsize=12)\n",
    "plt.colorbar(scatter)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"latent_space_tsne.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
